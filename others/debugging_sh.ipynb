{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "# torch.random.manual_seed(10)\n",
    "# torch.random.get_rng_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from:\n",
    "https://github.com/kazuto1011/cifar10-pytorch\n",
    "with an added BatchNorm layer at the start\n",
    "'''\n",
    "\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    ''' Basicblock: conv-batchnorm-relu with a residual connection. '''\n",
    "\n",
    "    def __init__(self, n_in, n_out, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.connection = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(n_in, n_out, 3, stride, 1, bias=False)),\n",
    "            ('norm1', nn.BatchNorm2d(n_out)),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ('conv2', nn.Conv2d(n_out, n_out, 3, 1, 1, bias=False)),\n",
    "            ('norm2', nn.BatchNorm2d(n_out)),\n",
    "        ]))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv2d(n_in, n_out, 1, stride, bias=False),\n",
    "            nn.BatchNorm2d(n_out),\n",
    "        )\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        mapping = self.connection(x)\n",
    "        if self.stride != 1:\n",
    "            x = self.downsample(x)\n",
    "        return self.relu(mapping + x)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    ''' n_block times the basicblock. '''\n",
    "\n",
    "    def __init__(self, n_in, n_out, n_block, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.blocks = nn.Sequential()\n",
    "        self.blocks.add_module('block0', BasicBlock(n_in, n_out, stride))\n",
    "        for i in range(n_block - 1):\n",
    "            block = BasicBlock(n_out, n_out)\n",
    "            self.blocks.add_module('block{}'.format(i + 1), block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.blocks(x)\n",
    "\n",
    "\n",
    "class ResNetCifar10(nn.Module):\n",
    "    ''' Residual network built for the CIFAR10 database. '''\n",
    "\n",
    "    def __init__(self, n_classes=2, n_block=3):\n",
    "        super(ResNetCifar10, self).__init__()\n",
    "        ch = [16, 32, 64]\n",
    "        self.bn0 = nn.BatchNorm2d(3, affine=True)\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(3, ch[0], 3, 1, 1, bias=False)),\n",
    "            ('norm1', nn.BatchNorm2d(ch[0])),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ('resb1', ResidualBlock(ch[0], ch[0], n_block)),\n",
    "            ('resb2', ResidualBlock(ch[0], ch[1], n_block, 2)),\n",
    "            ('resb3', ResidualBlock(ch[1], ch[2], n_block, 2)),\n",
    "            ('avgpl', nn.AvgPool2d(8)),\n",
    "        ]))\n",
    "        self.fc = nn.Linear(ch[2], n_classes)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn0(x)\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Patch-based deep learning spoof detection. '''\n",
    "\n",
    "import os\n",
    "import dlib\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "# from utils import networks\n",
    "\n",
    "# from document_check_framework.monitoring import logger\n",
    "# log = logger.get_logger(__name__)\n",
    "\n",
    "class EmptyVideoException(Exception):\n",
    "    ''' Exception to throw when the video is empty. '''\n",
    "    pass\n",
    "\n",
    "class FaceNotFoundException(Exception):\n",
    "    ''' Exception to throw when dlib face detection fails. '''\n",
    "    pass\n",
    "\n",
    "class NonRGBImageException(Exception):\n",
    "    ''' Exception to throw when the image is not an RGB image. '''\n",
    "    pass\n",
    "\n",
    "\n",
    "class spoof_detector(object):\n",
    "    ''' The object used to detect spoofs. '''\n",
    "\n",
    "    def __init__(self, network_location):\n",
    "        # size and patch_size are required to be 128 and 32 respectively\n",
    "        # size is the edge length to resize the image to before taking patches\n",
    "        # the n_blocks however can be changed freely - lower is faster\n",
    "        # it indicates the amount of patches to take horizontal and vertical\n",
    "        # recommended range for resolution is somewhere between 8 and 32\n",
    "        self.size = 128\n",
    "        self.patch_size = 32\n",
    "        self.n_blocks = 32\n",
    "        self.threshold = 0.90\n",
    "        self.threshold = float(self.threshold)\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        self.network = ResNetCifar10(4)\n",
    "#         filename = os.path.join(network_location, 'network_dict')\n",
    "        filename = network_location\n",
    "        state_dict = torch.load(filename, map_location=lambda s, loc: s)\n",
    "        self.network.load_state_dict(state_dict)\n",
    "        self.network.eval()\n",
    "        self.network.train(False)\n",
    "\n",
    "    def detect_face(self, img):\n",
    "        ''' Detect faces in the image and return crop of the largest face. '''\n",
    "        # detect face in all four rotations\n",
    "        # img is an RGB image with shape: (h, w, 3)\n",
    "        for r in range(4):\n",
    "            # rotate 90 * r degrees\n",
    "            # if we rotate we also need to copy otherwise\n",
    "            # dlib and pytorch receive a non-continuous ndarray\n",
    "            rotated_img = np.rot90(img, r).copy()\n",
    "            # detect faces\n",
    "            dets, conf, _ = self.detector.run(rotated_img)\n",
    "            # filter detections with conf <= 0\n",
    "            dets = [d for d, c in zip(dets, conf) if c > 0]\n",
    "            print(dets, conf)\n",
    "            # if at least one face was detected\n",
    "            if len(dets) > 0:\n",
    "                # calculate face sizes per detection\n",
    "                size = [d.bottom() - d.top() + d.right() - d.left() for d in dets]\n",
    "                # select detection corresponding with largest face\n",
    "                det = dets[np.argmax(size)]\n",
    "                # prevent top and left from becoming negative values\n",
    "                top, left = max(det.top(), 0), max(det.left(), 0)\n",
    "                bottom, right = det.bottom(), det.right()\n",
    "                # return cropped image\n",
    "                return rotated_img[top:bottom, left:right]\n",
    "        return None\n",
    "\n",
    "    def create_heatmap(self, face_crop):\n",
    "        '''\n",
    "        Predict uniformly sampled patches from the face_crop.\n",
    "        First create a batch containing all patches.\n",
    "        Then run the batch with patches through the network.\n",
    "        Return the output predictions reshaped as a heatmap.\n",
    "        '''\n",
    "        # face_crop is an RGB image with shape: (self.size, self.size, 3)\n",
    "        face_crop = face_crop.transpose(2, 0, 1)\n",
    "        _, h, w = face_crop.shape\n",
    "        # create a batch with uniformly sampled patches\n",
    "        hr = float(h - self.patch_size) / (self.n_blocks - 1)\n",
    "        wr = float(w - self.patch_size) / (self.n_blocks - 1)\n",
    "        # create empty batch\n",
    "        n_patches = self.n_blocks**2\n",
    "        batch = np.zeros((n_patches, 3, self.patch_size, self.patch_size))\n",
    "        for y in range(self.n_blocks):\n",
    "            for x in range(self.n_blocks):\n",
    "                y1 = int(y * hr)\n",
    "                y2 = int(y * hr + self.patch_size)\n",
    "                x1 = int(x * wr)\n",
    "                x2 = int(x * wr + self.patch_size)\n",
    "                patch_float = face_crop[:, y1:y2, x1:x2] / 255.0\n",
    "                batch[y * self.n_blocks + x, :, :, :] = patch_float\n",
    "        # network makes a prediction per patch\n",
    "        inputs = Variable(torch.from_numpy(batch).float(), volatile=True)\n",
    "        outputs = F.softmax(self.network(inputs)).data.cpu().numpy()\n",
    "        # reshape outputs into a heatmap where channels are class predictions:\n",
    "        # (genuine_sample, picture_attack, screen_attack and document_attack)\n",
    "        return outputs.reshape((self.n_blocks, self.n_blocks, -1))\n",
    "\n",
    "    def spoof(self, image):\n",
    "        '''\n",
    "        Turns input image into a spoof attempt prediction.\n",
    "        Note: a score of 1.0 indicates a genuine samples,\n",
    "        while a score of 0.0 indicates a spoofing attempt!\n",
    "        '''\n",
    "        # filter non RGB images\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "            raise NonRGBImageException\n",
    "        # detect face in image\n",
    "        face_crop = self.detect_face(image)\n",
    "        if face_crop is None:\n",
    "            raise FaceNotFoundException\n",
    "        # resize image\n",
    "        face_crop = imresize(face_crop, (self.size, self.size))\n",
    "        # spoof prediction\n",
    "        heatmap = self.create_heatmap(face_crop)\n",
    "        # transform heatmap into a genuine sample prediction\n",
    "        spoof_score = np.mean(heatmap[:, :, 0])\n",
    "        return spoof_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' API functions to call from the main service. '''\n",
    "\n",
    "import io\n",
    "import os\n",
    "# import av\n",
    "import PIL\n",
    "import numpy as np\n",
    "# from document_check_framework.imago import Imago\n",
    "# from document_check_framework.monitoring import logger\n",
    "# from ._methods.spoof_detection import spoof_detector, \\\n",
    "#     FaceNotFoundException, NonRGBImageException, EmptyVideoException\n",
    "# log = logger.get_logger(__name__)\n",
    "\n",
    "# EXIF_ORIENTATION_TAG = 274\n",
    "\n",
    "def score_photo(uuid, detector=None):\n",
    "    ''' Download image based on uuid and returns predicted spoof score. '''\n",
    "    if detector is None:\n",
    "        detector = spoof_detector(model_dict)\n",
    "    # download image using Imago and transform to numpy with PIL\n",
    "    img = Imago.Instance().get_object(uuid, 'live_photos')\n",
    "    img = PIL.Image.open(io.BytesIO(img.content))\n",
    "    # rotate image based on exif data\n",
    "    image = np.array(img, dtype=np.uint8)\n",
    "    if hasattr(img, '_getexif') and img._getexif() is not None:\n",
    "        if EXIF_ORIENTATION_TAG in img._getexif():\n",
    "            orientation = img._getexif()[EXIF_ORIENTATION_TAG]\n",
    "            if orientation in [3, 4]:\n",
    "                image = np.rot90(image, 2)\n",
    "            if orientation in [5, 6]:\n",
    "                image = np.rot90(image, 3)\n",
    "            if orientation in [7, 8]:\n",
    "                image = np.rot90(image, 1)\n",
    "    # detect spoof and return score\n",
    "    return detector.spoof(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 768, 3)\n"
     ]
    }
   ],
   "source": [
    "import os, cv2\n",
    "os.getcwd()\n",
    "image = '0a9a1f3b-e79e-4043-81bd-0518b683084e.jpg'\n",
    "image = '08a7ac11-a455-465a-9a6e-f2fded3a339b.jpg'\n",
    "im = cv2.imread(image, cv2.IMREAD_UNCHANGED)\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rectangle(238,404,610,775)] 1.20046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:123: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/root/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94968033"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "filename = '/media/dataserver/workspace/blanca/MSDNet-GCN/test/utils/network_dict'\n",
    "# state_dict = torch.load(filename, map_location=lambda s, loc: s)\n",
    "\n",
    "# network = ResNetCifar10(4)\n",
    "# network.load_state_dict(state_dict)\n",
    "# for i, j in state_dict.items(): print(i)\n",
    "detector = spoof_detector(filename)\n",
    "detector.spoof(im)\n",
    "\n",
    "# [rectangle(280,321,651,692)] 0.567812\n",
    "# [rectangle(238,404,610,775)] 1.20046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_OpenCV(path):\n",
    "        im = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "        im = cv2.resize(im, (256, 256))\n",
    "        return im\n",
    "\n",
    "input_path = '/workspace/blanca/training/train/good_fit/300w01_indoor_203.png'\n",
    "im = read_image_OpenCV(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
